# Wazuh GraphRAG æ•´åˆæ–‡ä»¶é›† - å®Œæ•´æŠ€è¡“æ–‡ä»¶

> æœ¬æ–‡ä»¶æ•´åˆäº†å°ˆæ¡ˆä¸­æ‰€æœ‰é‡è¦çš„ .md æ–‡ä»¶å…§å®¹ï¼Œç§»é™¤é‡è¤‡é …ç›®ä¸¦çµ±ä¸€çµ„ç¹”ï¼Œæä¾›å®Œæ•´çš„æŠ€è¡“åƒè€ƒã€‚

## ğŸ“‹ ç›®éŒ„

1. [å°ˆæ¡ˆæ¦‚è¿°èˆ‡æ¶æ§‹](#å°ˆæ¡ˆæ¦‚è¿°èˆ‡æ¶æ§‹)
2. [å¿«é€Ÿéƒ¨ç½²æŒ‡å—](#å¿«é€Ÿéƒ¨ç½²æŒ‡å—)
3. [AgenticRAG å¯¦ä½œè©³è§£](#agenticrag-å¯¦ä½œè©³è§£)
4. [Stage 3 ä»£ç†é—œè¯åˆ†æ](#stage-3-ä»£ç†é—œè¯åˆ†æ)
5. [ç›£æ§ç³»çµ±è¨­ç½®](#ç›£æ§ç³»çµ±è¨­ç½®)
6. [æ•ˆèƒ½å„ªåŒ–æŒ‡å—](#æ•ˆèƒ½å„ªåŒ–æŒ‡å—)
7. [å‘é‡åŒ–æŠ€è¡“è©³è§£](#å‘é‡åŒ–æŠ€è¡“è©³è§£)
8. [éƒ¨ç½²èˆ‡ç¶­é‹ç¸½çµ](#éƒ¨ç½²èˆ‡ç¶­é‹ç¸½çµ)
9. [æ•…éšœæ’é™¤æŒ‡å—](#æ•…éšœæ’é™¤æŒ‡å—)
10. [ç‰ˆæœ¬è®Šæ›´è¨˜éŒ„](#ç‰ˆæœ¬è®Šæ›´è¨˜éŒ„)

---

## å°ˆæ¡ˆæ¦‚è¿°èˆ‡æ¶æ§‹

### ğŸ¯ æ ¸å¿ƒæŠ€è¡“ç‰¹æ€§

**Wazuh GraphRAG** æ˜¯æ¥­ç•Œé¦–å‰µçš„å››éšæ®µæ¼”é€²å¼åœ–å½¢æª¢ç´¢å¢å¼·ç”Ÿæˆç³»çµ±ï¼Œå°ˆç‚ºå®‰å…¨é‹ç‡Ÿä¸­å¿ƒ (SOC) è¨­è¨ˆã€‚

#### å››éšæ®µæ¼”é€²æ¶æ§‹
1. **Stage 1: åŸºç¤å‘é‡åŒ–** - èªç¾©ç·¨ç¢¼èˆ‡ç´¢å¼•å»ºæ§‹
2. **Stage 2: æ ¸å¿ƒRAG** - æ­·å²æª¢ç´¢èˆ‡ä¸Šä¸‹æ–‡å¢å¼·
3. **Stage 3: AgenticRAG** - æ™ºèƒ½ä»£ç†æ±ºç­–èˆ‡å¤šç¶­åº¦æª¢ç´¢
4. **Stage 4: GraphRAG** - åœ–å½¢å¨è„…åˆ†æèˆ‡æ”»æ“Šè·¯å¾‘è­˜åˆ¥

#### æ ¸å¿ƒå‰µæ–°
- **Cypher è·¯å¾‘è¨˜è™Ÿ**: é¦–å‰µçš„åœ–å½¢é—œä¿‚ LLM è¡¨ç¤ºæ³•
- **æ··åˆæª¢ç´¢å¼•æ“**: åœ–å½¢éæ­· + å‘é‡æœç´¢çš„æ™ºèƒ½æ•´åˆ
- **Agentic æ±ºç­–å¼•æ“**: åŸºæ–¼è­¦å ±ç‰¹å¾µçš„è‡ªå‹•æª¢ç´¢ç­–ç•¥é¸æ“‡
- **å¨è„…å¯¦é«”æœ¬é«”**: å®Œæ•´çš„å®‰å…¨é ˜åŸŸçŸ¥è­˜åœ–è­œ

### ğŸ—ï¸ ç³»çµ±æ¶æ§‹

#### æŠ€è¡“å †ç–Šé…ç½®

| çµ„ä»¶ | æŠ€è¡“ | ç‰ˆæœ¬ | è·è²¬ |
|------|------|------|------|
| **SIEM å¹³å°** | Wazuh | 4.7.4 | å®‰å…¨ç›£æ§èˆ‡äº‹ä»¶ç®¡ç† |
| **åœ–å½¢è³‡æ–™åº«** | Neo4j Community | 5.15 | å¨è„…é—œä¿‚åœ–è­œå­˜å„² |
| **å‘é‡è³‡æ–™åº«** | OpenSearch KNN | - | èªç¾©å‘é‡ç´¢å¼•èˆ‡æª¢ç´¢ |
| **èªè¨€æ¨¡å‹** | Claude 3 Haiku / Gemini 1.5 Flash | - | å¨è„…åˆ†æèˆ‡å ±å‘Šç”Ÿæˆ |
| **åµŒå…¥æ¨¡å‹** | Google Gemini Embedding | text-embedding-004 | æ–‡æœ¬å‘é‡åŒ– |
| **API æœå‹™** | FastAPI + uvicorn | - | RESTful API èˆ‡å¥åº·ç›£æ§ |
| **æ’ç¨‹å™¨** | APScheduler | - | å®šæœŸè­¦å ±è™•ç†ä»»å‹™ |
| **ç›£æ§ç³»çµ±** | Prometheus + Grafana | 2.48.0 + 10.2.2 | æŒ‡æ¨™æ”¶é›†èˆ‡è¦–è¦ºåŒ– |

#### è³‡æ–™æµç¨‹æ¶æ§‹
```
æ–°è­¦å ± â†’ å‘é‡åŒ– â†’ ä»£ç†æ±ºç­– â†’ æ··åˆæª¢ç´¢ â†’ åœ–å½¢åˆ†æ â†’ LLM åˆ†æ â†’ çµæœå­˜å„²
   â†“        â†“        â†“         â†“         â†“        â†“         â†“
 åŸå§‹æ•¸æ“š  768ç¶­å‘é‡  æª¢ç´¢ç­–ç•¥   ä¸Šä¸‹æ–‡èšåˆ  è·¯å¾‘è­˜åˆ¥  å¨è„…å ±å‘Š  çŸ¥è­˜æ›´æ–°
```

---

## å¿«é€Ÿéƒ¨ç½²æŒ‡å—

### ğŸš€ ä¸€éµéƒ¨ç½²æµç¨‹

#### 1. ç’°å¢ƒæº–å‚™
```bash
# ç³»çµ±è¦æ±‚æª¢æŸ¥
free -h    # éœ€è¦ >= 8GB RAM
df -h      # éœ€è¦ >= 20GB ç£ç¢Ÿç©ºé–“
docker --version    # éœ€è¦ Docker 20.10+
docker-compose --version  # éœ€è¦ Docker Compose 2.0+

# å°ˆæ¡ˆè¨­ç½®
git clone <repository-url>
cd wazuh-docker/single-node
cp ai-agent-project/.env.example ai-agent-project/.env
```

#### 2. é—œéµç’°å¢ƒè®Šæ•¸é…ç½®
```env
# AI æœå‹™é…ç½®
GOOGLE_API_KEY=your_gemini_api_key_here
ANTHROPIC_API_KEY=your_anthropic_key_here
LLM_PROVIDER=anthropic  # æˆ– 'gemini'

# Neo4j åœ–å½¢è³‡æ–™åº«
NEO4J_URI=bolt://neo4j:7687
NEO4J_USER=neo4j
NEO4J_PASSWORD=wazuh-graph-2024

# OpenSearch é…ç½®
OPENSEARCH_URL=https://wazuh.indexer:9200
OPENSEARCH_USER=admin
OPENSEARCH_PASSWORD=SecretPassword

# ç›£æ§é…ç½®
PROMETHEUS_SCRAPE_INTERVAL=15s
GRAFANA_ADMIN_PASSWORD=wazuh-grafana-2024
```

#### 3. çµ±ä¸€éƒ¨ç½²åŸ·è¡Œ
```bash
# ç”Ÿæˆ SSL æ†‘è­‰
docker-compose -f generate-indexer-certs.yml run --rm generator

# å•Ÿå‹•å®Œæ•´å †ç–Š
chmod +x start-unified-stack.sh
./start-unified-stack.sh

# é©—è­‰éƒ¨ç½²
./health-check.sh --detailed
```

### ğŸ“Š æœå‹™å­˜å–é»ç¸½è¦½

| æœå‹™åç¨± | URL | é è¨­èªè­‰ | åŠŸèƒ½èªªæ˜ |
|----------|-----|----------|----------|
| Wazuh Dashboard | https://localhost:443 | admin/SecretPassword | SIEM ä¸»æ§å°èˆ‡è­¦å ±ç®¡ç† |
| AI Agent API | http://localhost:8000 | ç„¡éœ€èªè­‰ | GraphRAG API èˆ‡å¥åº·ç›£æ§ |
| Neo4j Browser | http://localhost:7474 | neo4j/wazuh-graph-2024 | åœ–å½¢è³‡æ–™åº«ç®¡ç†ä»‹é¢ |
| Grafana ç›£æ§ | http://localhost:3000 | admin/wazuh-grafana-2024 | æ•ˆèƒ½ç›£æ§å„€è¡¨æ¿ |
| Prometheus | http://localhost:9090 | ç„¡éœ€èªè­‰ | æŒ‡æ¨™æ”¶é›†èˆ‡æŸ¥è©¢ä»‹é¢ |
| Node Exporter | http://localhost:9100 | ç„¡éœ€èªè­‰ | ç³»çµ±æŒ‡æ¨™æš´éœ²ç«¯é» |

---

## AgenticRAG å¯¦ä½œè©³è§£

### ğŸ§  æ ¸å¿ƒæ¨¡çµ„æ¶æ§‹

#### 1. ä¸»ç¨‹å¼æ¨¡çµ„ (main.py)
**æ ¸å¿ƒè·è²¬**: ç³»çµ±å”èª¿å™¨èˆ‡ API æœå‹™æä¾›è€…

**é—œéµåŠŸèƒ½æ¨¡çµ„**:
- **éåŒæ­¥æ’ç¨‹**: æ¯ 60 ç§’åŸ·è¡Œè­¦å ±åˆ†æå¾ªç’°
- **LLM æä¾›å•†ç®¡ç†**: æ”¯æ´ Anthropic Claude èˆ‡ Google Gemini
- **RAG å·¥ä½œæµç¨‹**: å®Œæ•´çš„æª¢ç´¢å¢å¼·ç”Ÿæˆæµç¨‹
- **åœ–å½¢æŒä¹…åŒ–**: Neo4j å¨è„…å¯¦é«”èˆ‡é—œä¿‚ç®¡ç†

**æ ¸å¿ƒå‡½å¼èªªæ˜**:
```python
async def process_single_alert(alert: Dict) -> None:
    """å®Œæ•´çš„å–®ä¸€è­¦å ± RAG è™•ç†æµç¨‹
    
    å·¥ä½œæµç¨‹:
    1. è­¦å ±å‘é‡åŒ– (Gemini Embedding)
    2. ä»£ç†æ±ºç­– (Agentic Query Determination) 
    3. æ··åˆæª¢ç´¢ (Vector + Graph Search)
    4. ä¸Šä¸‹æ–‡çµ„è£ (Context Assembly)
    5. LLM åˆ†æ (Claude/Gemini Analysis)
    6. çµæœæŒä¹…åŒ– (Neo4j + OpenSearch)
    """

async def determine_contextual_queries(alert: Dict) -> List[Dict]:
    """Stage 3: Agentic æ±ºç­–å¼•æ“
    
    æ ¹æ“šè­¦å ±é¡å‹èˆ‡å…§å®¹æ™ºèƒ½æ±ºå®šæ‰€éœ€çš„ä¸Šä¸‹æ–‡è³‡è¨Š:
    - è³‡æºç›£æ§é—œè¯è¦å‰‡
    - å®‰å…¨äº‹ä»¶é—œè¯è¦å‰‡  
    - å”è­°ç‰¹å®šé—œè¯è¦å‰‡
    """

async def execute_retrieval(queries: List[Dict], vector: List[float]) -> Dict:
    """Stage 3: å¤šæºæª¢ç´¢åŸ·è¡Œå™¨
    
    åŒæ™‚åŸ·è¡Œå¤šç¨®æŸ¥è©¢é¡å‹ä¸¦èšåˆçµæœ:
    - k-NN å‘é‡ç›¸ä¼¼åº¦æœç´¢
    - åŸºæ–¼ä¸»æ©Ÿçš„æ™‚é–“çª—å£æŸ¥è©¢
    - å”è­°ç‰¹å®šçš„ä¸Šä¸‹æ–‡æª¢ç´¢
    """
```

#### 2. åµŒå…¥æœå‹™æ¨¡çµ„ (embedding_service.py)
**æ ¸å¿ƒè·è²¬**: æ–‡å­—å‘é‡åŒ–èˆ‡èªç¾©ç·¨ç¢¼

**æŠ€è¡“ç‰¹è‰²**:
- **MRL æ”¯æ´**: Matryoshka Representation Learningï¼Œæ”¯æ´ 1-768 ç¶­åº¦å½ˆæ€§èª¿æ•´
- **æŒ‡æ•¸é€€é¿é‡è©¦**: ç©©å®šçš„ API å‘¼å«èˆ‡å®¹éŒ¯æ©Ÿåˆ¶
- **è­¦å ±ç‰¹åŒ–è™•ç†**: é‡å° Wazuh è­¦å ±çµæ§‹å„ªåŒ–çš„å‘é‡åŒ–é‚è¼¯
- **å¥åº·æª¢æŸ¥**: å…§å»ºæœå‹™é€£ç·šæ¸¬è©¦èˆ‡è¨ºæ–·åŠŸèƒ½

**é—œéµé…ç½®åƒæ•¸**:
```python
EMBEDDING_CONFIG = {
    "model": "text-embedding-004",
    "dimensions": 768,          # å¯èª¿æ•´è‡³ 1-768
    "task_type": "SEMANTIC_SIMILARITY",
    "title": "Wazuh Security Alert",
    "output_dimensionality": 768
}
```

#### 3. ç´¢å¼•ç®¡ç†æ¨¡çµ„ (setup_index_template.py)
**æ ¸å¿ƒè·è²¬**: OpenSearch å‘é‡ç´¢å¼•ç¯„æœ¬ç®¡ç†

**HNSW ç´¢å¼•é…ç½®**:
```json
{
  "settings": {
    "index": {
      "knn": true,
      "knn.algo_param.ef_search": 512,
      "knn.algo_param.ef_construction": 512,
      "knn.algo_param.m": 16
    }
  },
  "mappings": {
    "properties": {
      "ai_analysis_vector": {
        "type": "knn_vector",
        "dimension": 768,
        "method": {
          "name": "hnsw",
          "space_type": "cosinesimil",
          "engine": "nmslib"
        }
      }
    }
  }
}
```

### ğŸ“Š æ•ˆèƒ½æœ€ä½³åŒ–é…ç½®

#### å‘é‡æœç´¢åƒæ•¸èª¿æ ¡
```python
# æœç´¢æ•ˆèƒ½å¹³è¡¡åƒæ•¸
VECTOR_SEARCH_K = 5              # k-NN è¿”å›æ•¸é‡
VECTOR_SIMILARITY_THRESHOLD = 0.7 # ç›¸ä¼¼åº¦é–€æª»
HNSW_EF_SEARCH = 512            # æœç´¢å€™é¸æ•¸
HNSW_M = 16                     # é€£æ¥æ•¸é‡

# LLM åˆ†æåƒæ•¸
LLM_TEMPERATURE = 0.1           # å‰µé€ æ€§åƒæ•¸
LLM_MAX_TOKENS = 2048          # æœ€å¤§ç”Ÿæˆé•·åº¦
LLM_TIMEOUT = 30               # API è¶…æ™‚æ™‚é–“
```

---

## Stage 3 ä»£ç†é—œè¯åˆ†æ

### ğŸ¯ Agentic æ±ºç­–å¼•æ“è©³è§£

#### 1. æ±ºç­–é‚è¼¯æ¶æ§‹

**æ ¸å¿ƒè¨­è¨ˆç†å¿µ**: å¾è¢«å‹•æª¢ç´¢è½‰å‘ä¸»å‹•æ™ºèƒ½æ±ºç­–

```python
def determine_contextual_queries(alert: Dict[str, Any]) -> List[Dict[str, Any]]:
    """
    Stage 3 æ ¸å¿ƒ: åŸºæ–¼è­¦å ±ç‰¹å¾µçš„æ™ºèƒ½ä¸Šä¸‹æ–‡æ±ºç­–å¼•æ“
    
    æ±ºç­–é‚è¼¯:
    1. é è¨­è¡Œç‚º: å§‹çµ‚åŸ·è¡Œ k-NN å‘é‡æœç´¢ (å‘å¾Œç›¸å®¹)
    2. æ¢ä»¶è§¸ç™¼: åŸºæ–¼è­¦å ±é¡å‹çš„ç‰¹å®šæª¢ç´¢ç­–ç•¥
    3. å¤šç¶­èšåˆ: æ•´åˆå¤šç¨®è³‡æ–™æºçš„ç›¸é—œè³‡è¨Š
    """
```

#### 2. é—œè¯è¦å‰‡é«”ç³»

**è³‡æºç›£æ§é—œè¯è¦å‰‡**:
```python
# è§¸ç™¼æ¢ä»¶
RESOURCE_TRIGGERS = [
    "High CPU usage detected",
    "Excessive RAM consumption", 
    "Memory usage critical",
    "Disk space low"
]

# åŸ·è¡Œå‹•ä½œ
RESOURCE_ACTIONS = {
    "query_type": "host_processes",
    "time_window": "5m",        # 5åˆ†é˜æ™‚é–“çª—å£
    "target_field": "agent.name",
    "context_type": "process_correlation"
}
```

**å®‰å…¨äº‹ä»¶é—œè¯è¦å‰‡**:
```python
# è§¸ç™¼æ¢ä»¶  
SECURITY_TRIGGERS = [
    "SSH brute-force attack",
    "Web attack detected",
    "Authentication failure",
    "Suspicious login attempt"
]

# åŸ·è¡Œå‹•ä½œ
SECURITY_ACTIONS = [
    {
        "query_type": "host_cpu_metrics", 
        "time_window": "1m",
        "context_type": "performance_correlation"
    },
    {
        "query_type": "host_network_io",
        "time_window": "1m", 
        "context_type": "network_correlation"
    }
]
```

#### 3. å¤šæºæª¢ç´¢åŸ·è¡Œå™¨

**åŒæ­¥åŸ·è¡Œæ¶æ§‹**:
```python
async def execute_retrieval(queries: List[Dict], alert_vector: List[float]) -> Dict:
    """
    ä¸¦è¡ŒåŸ·è¡Œå¤šç¨®æª¢ç´¢ç­–ç•¥:
    1. Vector Search: k-NN èªç¾©ç›¸ä¼¼åº¦æª¢ç´¢
    2. Temporal Search: æ™‚é–“çª—å£ç›¸é—œäº‹ä»¶æª¢ç´¢  
    3. Host-based Search: ä¸»æ©Ÿç‰¹å®šä¸Šä¸‹æ–‡æª¢ç´¢
    4. Protocol-specific Search: å”è­°ç›¸é—œæª¢ç´¢
    """
    
    results = {
        "similar_alerts": [],
        "host_context": [],
        "temporal_context": [],
        "protocol_context": []
    }
    
    # ä¸¦è¡ŒåŸ·è¡Œæ‰€æœ‰æŸ¥è©¢
    tasks = []
    for query in queries:
        if query["type"] == "vector_search":
            tasks.append(vector_search(alert_vector, query["k"]))
        elif query["type"] == "host_processes":
            tasks.append(host_process_search(query))
        elif query["type"] == "temporal_events":
            tasks.append(temporal_event_search(query))
    
    # èšåˆçµæœ
    query_results = await asyncio.gather(*tasks, return_exceptions=True)
    return aggregate_context_results(query_results)
```

### ğŸ“ˆ Agentic æ•ˆèƒ½æå‡æŒ‡æ¨™

| æŒ‡æ¨™é …ç›® | Stage 2 åŸºæº– | Stage 3 Agentic | æå‡å¹…åº¦ |
|----------|-------------|----------------|----------|
| ä¸Šä¸‹æ–‡ç›¸é—œæ€§ | 72% | 89% | +23.6% |
| å¨è„…æª¢æ¸¬æº–ç¢ºæ€§ | 78% | 92% | +17.9% |
| åˆ†ææ·±åº¦ | åŸºç¤ | å¤šç¶­åº¦ | +200% |
| æª¢ç´¢ç­–ç•¥æ•¸é‡ | 1 (å‘é‡) | 8 (å¤šç¶­) | +700% |

---

## ç›£æ§ç³»çµ±è¨­ç½®

### ğŸ—ï¸ ç›£æ§æ¶æ§‹è¨­è¨ˆ

#### æ•´é«”ç›£æ§æµç¨‹
```
AI Agent (æŒ‡æ¨™æš´éœ²) â†’ Prometheus (æŠ“å–å­˜å„²) â†’ Grafana (æŸ¥è©¢è¦–è¦ºåŒ–)
     â†“                      â†“                    â†“
  /metrics ç«¯é»         æ™‚åºè³‡æ–™åº«           ç›£æ§å„€è¡¨æ¿
```

#### é—œéµæ•ˆèƒ½æŒ‡æ¨™ (KPIs)

**å»¶é²æŒ‡æ¨™ (Latency Metrics)**:
```python
# Prometheus æŒ‡æ¨™å®šç¾©
alert_processing_duration = Histogram(
    'alert_processing_duration_seconds',
    'Total time to process a single alert',
    buckets=[0.1, 0.5, 1.0, 2.0, 5.0, 10.0, 30.0]
)

api_call_duration = Histogram(
    'api_call_duration_seconds', 
    'Duration of API calls by stage',
    ['stage'],  # æ¨™ç±¤: embedding, llm, neo4j
    buckets=[0.01, 0.05, 0.1, 0.5, 1.0, 2.0, 5.0]
)

retrieval_duration = Histogram(
    'retrieval_duration_seconds',
    'Time spent on data retrieval operations', 
    ['retrieval_type'],  # æ¨™ç±¤: vector, graph, hybrid
    buckets=[0.01, 0.05, 0.1, 0.2, 0.5, 1.0]
)
```

**Token ä½¿ç”¨æŒ‡æ¨™**:
```python
llm_input_tokens = Counter(
    'llm_input_tokens_total',
    'Total input tokens used by LLM analysis',
    ['model_provider']  # anthropic, gemini
)

llm_output_tokens = Counter(
    'llm_output_tokens_total', 
    'Total output tokens generated by LLM',
    ['model_provider']
)

embedding_tokens = Counter(
    'embedding_input_tokens_total',
    'Total tokens used for embedding generation'
)
```

**ååé‡èˆ‡ä½‡åˆ—æŒ‡æ¨™**:
```python
alerts_processed = Counter(
    'alerts_processed_total',
    'Total number of alerts successfully processed',
    ['status']  # success, error
)

pending_alerts = Gauge(
    'pending_alerts_gauge', 
    'Current number of alerts pending processing'
)

new_alerts_found = Counter(
    'new_alerts_found_total',
    'Number of new alerts found in each polling cycle'
)
```

### ğŸ“Š Grafana å„€è¡¨æ¿é…ç½®

#### æ ¸å¿ƒç›£æ§é¢æ¿

**1. è­¦å ±è™•ç†æ•ˆèƒ½é¢æ¿**:
```json
{
  "title": "Alert Processing Performance",
  "panels": [
    {
      "title": "Processing Rate",
      "type": "graph", 
      "targets": [
        {
          "expr": "rate(alerts_processed_total[5m])",
          "legendFormat": "Alerts/sec"
        }
      ]
    },
    {
      "title": "Processing Latency (P50/P95/P99)",
      "type": "graph",
      "targets": [
        {
          "expr": "histogram_quantile(0.50, rate(alert_processing_duration_seconds_bucket[5m]))",
          "legendFormat": "P50"
        },
        {
          "expr": "histogram_quantile(0.95, rate(alert_processing_duration_seconds_bucket[5m]))", 
          "legendFormat": "P95"
        }
      ]
    }
  ]
}
```

**2. ç³»çµ±è³‡æºç›£æ§é¢æ¿**:
```json
{
  "title": "System Resources",
  "panels": [
    {
      "title": "Memory Usage",
      "type": "graph",
      "targets": [
        {
          "expr": "(node_memory_MemTotal_bytes - node_memory_MemAvailable_bytes) / node_memory_MemTotal_bytes * 100",
          "legendFormat": "Memory %"
        }
      ]
    },
    {
      "title": "CPU Usage", 
      "type": "graph",
      "targets": [
        {
          "expr": "100 - (avg by (instance) (rate(node_cpu_seconds_total{mode=\"idle\"}[5m])) * 100)",
          "legendFormat": "CPU %"
        }
      ]
    }
  ]
}
```

### ğŸ”§ Prometheus é…ç½®

#### æ ¸å¿ƒæŠ“å–é…ç½®
```yaml
# prometheus.yml
global:
  scrape_interval: 15s
  evaluation_interval: 15s

rule_files:
  - "alert_rules.yml"

scrape_configs:
  - job_name: 'ai-agent'
    static_configs:
      - targets: ['ai-agent:8000']
    metrics_path: '/metrics'
    scrape_interval: 10s
    
  - job_name: 'node-exporter'
    static_configs:
      - targets: ['node-exporter:9100']
    scrape_interval: 15s
    
  - job_name: 'neo4j'
    static_configs:
      - targets: ['neo4j:2004']
    scrape_interval: 30s

alerting:
  alertmanagers:
    - static_configs:
        - targets: ['localhost:9093']
```

#### å‘Šè­¦è¦å‰‡é…ç½®
```yaml
# alert_rules.yml
groups:
  - name: wazuh_graphrag_alerts
    rules:
      - alert: HighAlertProcessingLatency
        expr: histogram_quantile(0.95, rate(alert_processing_duration_seconds_bucket[5m])) > 5
        for: 2m
        labels:
          severity: warning
        annotations:
          summary: "Alert processing latency is high"
          
      - alert: AIAgentDown
        expr: up{job="ai-agent"} == 0
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "AI Agent is down"
```

---

## æ•ˆèƒ½å„ªåŒ–æŒ‡å—

### ğŸš€ ç³»çµ±æ•ˆèƒ½èª¿æ ¡

#### 1. Neo4j è¨˜æ†¶é«”å„ªåŒ–
```bash
# docker-compose.neo4j.yml ä¸­çš„ç’°å¢ƒè®Šæ•¸
NEO4J_dbms_memory_heap_max__size=4G        # å †è¨˜æ†¶é«”ä¸Šé™
NEO4J_dbms_memory_pagecache_size=1G        # é é¢å¿«å–å¤§å°
NEO4J_dbms_memory_transaction_max_size=1G   # äº¤æ˜“è¨˜æ†¶é«”ä¸Šé™

# æŸ¥è©¢æ•ˆèƒ½å„ªåŒ–
NEO4J_dbms_query_cache_size=10000          # æŸ¥è©¢å¿«å–å¤§å°
NEO4J_dbms_tx_log_rotation_retention_policy=100M  # äº¤æ˜“æ—¥èªŒä¿ç•™
```

#### 2. OpenSearch å‘é‡ç´¢å¼•èª¿æ ¡
```python
# HNSW æ¼”ç®—æ³•åƒæ•¸èª¿æ•´
VECTOR_INDEX_SETTINGS = {
    "knn.algo_param.ef_search": 256,       # æœç´¢å€™é¸æ•¸ (é è¨­: 512)
    "knn.algo_param.ef_construction": 256, # å»ºæ§‹å€™é¸æ•¸ (é è¨­: 512) 
    "knn.algo_param.m": 16,               # é€£æ¥æ•¸é‡ (é è¨­: 16)
    "index.refresh_interval": "30s",       # ç´¢å¼•åˆ·æ–°é–“éš”
    "index.number_of_shards": 1,          # åˆ†ç‰‡æ•¸é‡
    "index.number_of_replicas": 0         # å‰¯æœ¬æ•¸é‡
}

# æŸ¥è©¢æ•ˆèƒ½èª¿æ ¡
SEARCH_PARAMS = {
    "size": 5,                            # è¿”å›çµæœæ•¸é‡
    "min_score": 0.7,                     # æœ€ä½ç›¸ä¼¼åº¦åˆ†æ•¸
    "_source": ["timestamp", "rule.description", "ai_analysis"],  # åƒ…è¿”å›å¿…è¦æ¬„ä½
    "timeout": "5s"                       # æŸ¥è©¢è¶…æ™‚æ™‚é–“
}
```

#### 3. LLM API æ•ˆèƒ½å„ªåŒ–
```python
# Claude API å„ªåŒ–é…ç½®
CLAUDE_CONFIG = {
    "model": "claude-3-haiku-20240307",    # ä½¿ç”¨è¼ƒå¿«çš„ Haiku æ¨¡å‹
    "max_tokens": 1500,                   # æ¸›å°‘æœ€å¤§ç”Ÿæˆé•·åº¦
    "temperature": 0.1,                   # é™ä½éš¨æ©Ÿæ€§æå‡ä¸€è‡´æ€§
    "timeout": 25,                        # API è¶…æ™‚è¨­å®š
    "retry_attempts": 2,                  # é‡è©¦æ¬¡æ•¸
    "backoff_factor": 1.5                 # æŒ‡æ•¸é€€é¿å› å­
}

# Gemini API å„ªåŒ–é…ç½®  
GEMINI_CONFIG = {
    "model": "gemini-1.5-flash",          # ä½¿ç”¨è¼ƒå¿«çš„ Flash æ¨¡å‹
    "generation_config": {
        "max_output_tokens": 1500,
        "temperature": 0.1,
        "candidate_count": 1
    },
    "safety_settings": [                  # ç°¡åŒ–å®‰å…¨è¨­å®š
        {"category": "HARM_CATEGORY_HARASSMENT", "threshold": "BLOCK_NONE"}
    ]
}
```

### ğŸ“Š æ•ˆèƒ½ç›£æ§æœ€ä½³å¯¦è¸

#### é—œéµæ•ˆèƒ½æŒ‡æ¨™åŸºæº–
```python
# æ•ˆèƒ½ç›®æ¨™è¨­å®š
PERFORMANCE_TARGETS = {
    "alert_processing_p95": 3.0,          # 95% è­¦å ±è™•ç†æ™‚é–“ < 3ç§’
    "vector_search_p95": 0.2,             # 95% å‘é‡æœç´¢æ™‚é–“ < 200ms
    "graph_query_p95": 0.05,              # 95% åœ–å½¢æŸ¥è©¢æ™‚é–“ < 50ms
    "llm_analysis_p95": 2.0,              # 95% LLM åˆ†ææ™‚é–“ < 2ç§’
    "throughput_target": 15,              # ç›®æ¨™ååé‡ 15 è­¦å ±/åˆ†é˜
    "error_rate_threshold": 0.05          # éŒ¯èª¤ç‡é–¾å€¼ < 5%
}
```

#### æ•ˆèƒ½ç“¶é ¸è­˜åˆ¥
```bash
# 1. æŸ¥çœ‹å„éšæ®µå»¶é²åˆ†ä½ˆ
curl -s http://localhost:9090/api/v1/query?query='histogram_quantile(0.95, rate(api_call_duration_seconds_bucket[5m]))'

# 2. è­˜åˆ¥æœ€æ…¢çš„è™•ç†éšæ®µ
curl -s http://localhost:9090/api/v1/query?query='avg by (stage) (rate(api_call_duration_seconds_sum[5m]) / rate(api_call_duration_seconds_count[5m]))'

# 3. ç›£æ§ç³»çµ±è³‡æºä½¿ç”¨
curl -s http://localhost:9090/api/v1/query?query='rate(node_cpu_seconds_total{mode!="idle"}[5m])'
```

---

## å‘é‡åŒ–æŠ€è¡“è©³è§£

### ğŸ§  èªç¾©å‘é‡åŒ–æ¶æ§‹

#### 1. Gemini Embedding æ¨¡å‹ç‰¹æ€§

**æ¨¡å‹è¦æ ¼**:
- **æ¨¡å‹åç¨±**: `text-embedding-004` 
- **å‘é‡ç¶­åº¦**: 768 ç¶­ (æ”¯æ´ MRL å‹•æ…‹èª¿æ•´è‡³ 1-768)
- **ä¸Šä¸‹æ–‡é•·åº¦**: æœ€å¤§ 2048 tokens
- **èªè¨€æ”¯æ´**: å¤šèªè¨€ï¼ŒåŒ…å«ç¹é«”ä¸­æ–‡
- **ä»»å‹™é¡å‹**: `SEMANTIC_SIMILARITY` å°ˆé–€å„ªåŒ–

**MRL (Matryoshka Representation Learning) æ”¯æ´**:
```python
# å‹•æ…‹ç¶­åº¦èª¿æ•´ç¯„ä¾‹
EMBEDDING_CONFIGS = {
    "full_precision": {"dimensions": 768},      # å®Œæ•´ç²¾åº¦
    "high_precision": {"dimensions": 512},      # é«˜ç²¾åº¦ 
    "medium_precision": {"dimensions": 256},    # ä¸­ç­‰ç²¾åº¦
    "low_precision": {"dimensions": 128}        # ä½ç²¾åº¦ (å¿«é€Ÿæª¢ç´¢)
}

# æ ¹æ“šå ´æ™¯é¸æ“‡é©ç•¶ç¶­åº¦
def get_embedding_config(scenario: str) -> dict:
    if scenario == "detailed_analysis":
        return EMBEDDING_CONFIGS["full_precision"]
    elif scenario == "real_time_detection":
        return EMBEDDING_CONFIGS["low_precision"] 
    else:
        return EMBEDDING_CONFIGS["medium_precision"]
```

#### 2. è­¦å ±ç‰¹åŒ–å‘é‡åŒ–æµç¨‹

**æ–‡æœ¬é è™•ç†ç®¡é“**:
```python
def preprocess_alert_for_embedding(alert: Dict[str, Any]) -> str:
    """
    Wazuh è­¦å ±ç‰¹åŒ–çš„æ–‡æœ¬é è™•ç†æµç¨‹:
    1. é—œéµæ¬„ä½æå–èˆ‡çµæ§‹åŒ–
    2. å†—é¤˜è³‡è¨Šç§»é™¤èˆ‡æ¸…ç†  
    3. å®‰å…¨è¡“èªæ¨™æº–åŒ–
    4. ä¸Šä¸‹æ–‡è³‡è¨Šå¢å¼·
    """
    
    # æ ¸å¿ƒæ¬„ä½æå–
    core_fields = {
        "rule_description": alert.get("rule", {}).get("description", ""),
        "agent_info": f"{alert.get('agent', {}).get('name', '')} - {alert.get('agent', {}).get('ip', '')}",
        "timestamp": alert.get("timestamp", ""),
        "rule_level": alert.get("rule", {}).get("level", ""),
        "rule_groups": " ".join(alert.get("rule", {}).get("groups", []))
    }
    
    # çµæ§‹åŒ–æ–‡æœ¬çµ„è£
    structured_text = f"""
    Security Alert Analysis:
    Rule: {core_fields['rule_description']}
    Severity Level: {core_fields['rule_level']}
    Agent: {core_fields['agent_info']}
    Categories: {core_fields['rule_groups']}
    Timestamp: {core_fields['timestamp']}
    """
    
    return clean_and_normalize(structured_text)
```

#### 3. å‘é‡ç´¢å¼•ç­–ç•¥

**HNSW ç´¢å¼•é…ç½®è©³è§£**:
```json
{
  "index": {
    "knn": true,
    "knn.space_type": "cosinesimil",        // é¤˜å¼¦ç›¸ä¼¼åº¦ (é©åˆèªç¾©æœå°‹)
    "knn.algo_param": {
      "ef_search": 512,                     // æœå°‹æ™‚çš„å€™é¸æ•¸é‡
      "ef_construction": 512,               // å»ºæ§‹æ™‚çš„å€™é¸æ•¸é‡  
      "m": 16                              // æ¯å€‹ç¯€é»çš„é€£æ¥æ•¸é‡
    }
  },
  "mapping": {
    "properties": {
      "ai_analysis_vector": {
        "type": "knn_vector",
        "dimension": 768,
        "method": {
          "name": "hnsw",                   // Hierarchical NSW æ¼”ç®—æ³•
          "space_type": "cosinesimil",
          "engine": "nmslib"                // é«˜æ•ˆèƒ½å‘é‡æª¢ç´¢å¼•æ“
        }
      }
    }
  }
}
```

### ğŸ“ˆ å‘é‡åŒ–æ•ˆèƒ½åŸºæº–

#### å‘é‡åŒ–è™•ç†æ•ˆèƒ½
| æŒ‡æ¨™ | æ•¸å€¼ | åŸºæº– |
|------|------|------|
| å–®æ¬¡å‘é‡åŒ–å»¶é² | ~45-60ms | <100ms |
| æ‰¹æ¬¡è™•ç†èƒ½åŠ› | 20 è­¦å ±/æ‰¹æ¬¡ | 10+ è­¦å ±/æ‰¹æ¬¡ |
| å‘é‡æª¢ç´¢å»¶é² | ~15-25ms | <50ms |
| ç´¢å¼•æ›´æ–°å»¶é² | ~5-10ms | <20ms |

#### ç›¸ä¼¼åº¦æª¢ç´¢æº–ç¢ºæ€§
```python
# ç›¸ä¼¼åº¦é–¾å€¼é…ç½®
SIMILARITY_THRESHOLDS = {
    "high_relevance": 0.85,     # é«˜åº¦ç›¸é—œ (æ¨è–¦é–¾å€¼)
    "medium_relevance": 0.75,   # ä¸­åº¦ç›¸é—œ
    "low_relevance": 0.65,      # ä½åº¦ç›¸é—œ  
    "minimum_threshold": 0.6    # æœ€ä½é–¾å€¼
}

# æª¢ç´¢ç­–ç•¥é…ç½®
RETRIEVAL_STRATEGY = {
    "k": 5,                     # è¿”å›å‰ 5 å€‹æœ€ç›¸ä¼¼çµæœ
    "threshold": 0.75,          # ç›¸ä¼¼åº¦é–€æª»
    "boost_recent": True,       # æå‡è¿‘æœŸè­¦å ±æ¬Šé‡
    "time_decay_factor": 0.1    # æ™‚é–“è¡°æ¸›å› å­
}
```

---

## éƒ¨ç½²èˆ‡ç¶­é‹ç¸½çµ

### ğŸ¯ çµ±ä¸€å †ç–Šéƒ¨ç½²æˆæœ

#### å®Œæˆçš„æ¶æ§‹çµ„ä»¶
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    çµ±ä¸€ Docker ç¶²è·¯                             â”‚
â”‚                 wazuh-graphrag-network                          â”‚
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚  â”‚    Wazuh     â”‚  â”‚  AI Agent    â”‚  â”‚    Neo4j     â”‚         â”‚
â”‚  â”‚   Security   â”‚â—„â”€â”¤ (GraphRAG)   â”œâ”€â–ºâ”‚   Graph DB   â”‚         â”‚
â”‚  â”‚   Platform   â”‚  â”‚              â”‚  â”‚              â”‚         â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â”‚                           â”‚                                    â”‚
â”‚                           â–¼                                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                ç›£æ§å †ç–Š                                  â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚   â”‚
â”‚  â”‚  â”‚ Prometheus  â”‚â”€â”€â”€â–ºâ”‚   Grafana   â”‚    â”‚    Node     â”‚ â”‚   â”‚
â”‚  â”‚  â”‚             â”‚    â”‚             â”‚    â”‚  Exporter   â”‚ â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### é—œéµç®¡ç†è…³æœ¬
```bash
# çµ±ä¸€å•Ÿå‹•è…³æœ¬ (start-unified-stack.sh)
#!/bin/bash
echo "ğŸš€ å•Ÿå‹• Wazuh GraphRAG çµ±ä¸€å †ç–Š..."

# é å…ˆæª¢æŸ¥
./health-check.sh --pre-check

# åˆ†éšæ®µå•Ÿå‹•
docker-compose -f docker-compose.main.yml up -d wazuh.indexer
echo "â³ ç­‰å¾… Wazuh Indexer å•Ÿå‹•..."
sleep 30

docker-compose -f docker-compose.main.yml up -d wazuh.manager  
docker-compose -f docker-compose.main.yml up -d wazuh.dashboard
echo "â³ ç­‰å¾… Wazuh æ ¸å¿ƒæœå‹™å•Ÿå‹•..."
sleep 60

docker-compose -f docker-compose.main.yml up -d neo4j
docker-compose -f docker-compose.main.yml up -d ai-agent
echo "â³ ç­‰å¾… GraphRAG æœå‹™å•Ÿå‹•..."
sleep 30

docker-compose -f docker-compose.main.yml up -d prometheus grafana node-exporter
echo "âœ… çµ±ä¸€å †ç–Šå•Ÿå‹•å®Œæˆï¼"

# å¾Œç½®å¥åº·æª¢æŸ¥
./health-check.sh --post-deploy
```

### ğŸ› ï¸ é‹ç¶­æœ€ä½³å¯¦è¸

#### 1. å®šæœŸç¶­è­·ä»»å‹™
```bash
# æ¯æ—¥ç¶­è­·è…³æœ¬ (daily-maintenance.sh)
#!/bin/bash

# æ¸…ç† Docker ç³»çµ±
docker system prune -f

# æª¢æŸ¥ç£ç¢Ÿç©ºé–“
df -h | awk 'NR>1{if($5>80) print "è­¦å‘Š: "$6" ç£ç¢Ÿä½¿ç”¨ç‡é”åˆ° "$5}'

# å‚™ä»½ Neo4j è³‡æ–™
docker-compose -f docker-compose.main.yml exec neo4j \
  neo4j-admin dump --database=neo4j --to=/backups/neo4j-backup-$(date +%Y%m%d).dump

# æª¢æŸ¥æœå‹™å¥åº·ç‹€æ…‹
./health-check.sh --automated
```

#### 2. æ•ˆèƒ½ç›£æ§æª¢æŸ¥æ¸…å–®
```bash
# æ¯å°æ™‚åŸ·è¡Œçš„æ•ˆèƒ½æª¢æŸ¥
PERFORMANCE_CHECKS=(
    "è­¦å ±è™•ç†å»¶é² < 3ç§’"
    "è¨˜æ†¶é«”ä½¿ç”¨ç‡ < 85%"  
    "CPU ä½¿ç”¨ç‡ < 80%"
    "ç£ç¢Ÿä½¿ç”¨ç‡ < 90%"
    "Neo4j å †è¨˜æ†¶é«”ä½¿ç”¨ < 3.5GB"
    "API éŒ¯èª¤ç‡ < 5%"
)

# Grafana å‘Šè­¦è¦å‰‡
GRAFANA_ALERTS=(
    "AI Agent æœå‹™åœæ©Ÿå‘Šè­¦"
    "é«˜å»¶é²è™•ç†å‘Šè­¦ (P95 > 5ç§’)"
    "è¨˜æ†¶é«”ä½¿ç”¨éé«˜å‘Šè­¦ (> 90%)"
    "ç£ç¢Ÿç©ºé–“ä¸è¶³å‘Šè­¦ (< 2GB)"
)
```

### ğŸ“Š ç¶­é‹æŒ‡æ¨™å„€è¡¨æ¿

#### æ ¸å¿ƒ KPI ç›£æ§
```yaml
# ç¶­é‹é—œéµæŒ‡æ¨™
operational_kpis:
  availability:
    target: 99.9%
    measurement: "æœå‹™æ­£å¸¸é‹è¡Œæ™‚é–“"
    
  performance:
    alert_processing_p95: "<3ç§’"
    throughput: ">10 è­¦å ±/åˆ†é˜"
    error_rate: "<2%"
    
  resource_utilization:
    memory_usage: "<85%"
    cpu_usage: "<80%" 
    disk_usage: "<90%"
    
  business_metrics:
    threat_detection_accuracy: ">90%"
    false_positive_rate: "<5%"
    analyst_time_saved: ">70%"
```

---

## æ•…éšœæ’é™¤æŒ‡å—

### ğŸš¨ å¸¸è¦‹å•é¡Œèˆ‡è§£æ±ºæ–¹æ¡ˆ

#### 1. æœå‹™å•Ÿå‹•å•é¡Œ

**å•é¡Œ**: Docker å®¹å™¨å•Ÿå‹•å¤±æ•—
```bash
# è¨ºæ–·æ­¥é©Ÿ
# 1. æª¢æŸ¥ç³»çµ±è³‡æº
free -h && df -h

# 2. æª¢æŸ¥ Docker æœå‹™ç‹€æ…‹
systemctl status docker
docker system df

# 3. æŸ¥çœ‹å…·é«”éŒ¯èª¤æ—¥èªŒ
docker-compose -f docker-compose.main.yml logs --tail=50 [service-name]

# è§£æ±ºæ–¹æ¡ˆ
# æ¸…ç† Docker ç³»çµ±
docker system prune -af
docker volume prune -f

# é‡æ–°å•Ÿå‹• Docker æœå‹™
sudo systemctl restart docker
```

**å•é¡Œ**: SSL æ†‘è­‰ç›¸é—œéŒ¯èª¤
```bash
# è¨ºæ–·èˆ‡ä¿®å¾©
# 1. æª¢æŸ¥æ†‘è­‰æª”æ¡ˆ
ls -la config/wazuh_indexer_ssl_certs/

# 2. é‡æ–°ç”Ÿæˆæ†‘è­‰
docker-compose -f generate-indexer-certs.yml down
docker-compose -f generate-indexer-certs.yml run --rm generator

# 3. æª¢æŸ¥æ†‘è­‰æœ‰æ•ˆæ€§
openssl x509 -in config/wazuh_indexer_ssl_certs/wazuh.indexer.pem -text -noout
```

#### 2. Neo4j é€£æ¥å•é¡Œ

**å•é¡Œ**: Neo4j è³‡æ–™åº«é€£æ¥å¤±æ•—
```bash
# è¨ºæ–·æ­¥é©Ÿ
# 1. æª¢æŸ¥ Neo4j æœå‹™ç‹€æ…‹
docker-compose -f docker-compose.main.yml ps neo4j
docker-compose -f docker-compose.main.yml logs neo4j

# 2. æ¸¬è©¦é€£æ¥
docker-compose -f docker-compose.main.yml exec neo4j \
  cypher-shell -u neo4j -p wazuh-graph-2024 "MATCH (n) RETURN count(n);"

# è§£æ±ºæ–¹æ¡ˆ
# é‡ç½® Neo4j è³‡æ–™åº«
docker-compose -f docker-compose.main.yml stop neo4j
docker volume rm single-node_neo4j_data single-node_neo4j_logs
docker-compose -f docker-compose.main.yml up -d neo4j

# ç­‰å¾…åˆå§‹åŒ–å®Œæˆ (ç´„ 2-3 åˆ†é˜)
sleep 180
```

**å•é¡Œ**: Neo4j è¨˜æ†¶é«”ä¸è¶³
```bash
# èª¿æ•´è¨˜æ†¶é«”é…ç½®
# ç·¨è¼¯ ai-agent-project/docker-compose.neo4j.yml
NEO4J_dbms_memory_heap_max__size=4G
NEO4J_dbms_memory_pagecache_size=1G

# é‡æ–°å•Ÿå‹•æœå‹™
docker-compose -f docker-compose.main.yml restart neo4j
```

#### 3. AI Agent åˆ†æå•é¡Œ

**å•é¡Œ**: API é‡‘é‘°é…ç½®éŒ¯èª¤
```bash
# æª¢æŸ¥é…ç½®
cat ai-agent-project/.env | grep -E "(GOOGLE_API_KEY|ANTHROPIC_API_KEY|LLM_PROVIDER)"

# æ¸¬è©¦ API é€£æ¥
docker-compose -f docker-compose.main.yml exec ai-agent \
  python -c "
import os
from embedding_service import test_connection
result = test_connection()
print(f'API é€£æ¥æ¸¬è©¦: {result}')
"
```

**å•é¡Œ**: å‘é‡åŒ–æœå‹™å¤±æ•—
```bash
# åŸ·è¡Œå®Œæ•´é©—è­‰
docker-compose -f docker-compose.main.yml exec ai-agent \
  python /app/verify_vectorization.py

# æª¢æŸ¥ OpenSearch ç´¢å¼•ç‹€æ…‹
curl -k -u admin:SecretPassword \
  "https://localhost:9200/_cat/indices/wazuh-alerts-*?v&s=index"

# é‡å»ºå‘é‡ç´¢å¼• (å¦‚éœ€è¦)
docker-compose -f docker-compose.main.yml exec ai-agent \
  python /app/setup_index_template.py
```

#### 4. ç›£æ§ç³»çµ±å•é¡Œ

**å•é¡Œ**: Prometheus ç„¡æ³•æŠ“å–æŒ‡æ¨™
```bash
# æª¢æŸ¥ Prometheus é…ç½®
docker-compose -f docker-compose.main.yml exec prometheus \
  cat /etc/prometheus/prometheus.yml

# æª¢æŸ¥ç›®æ¨™ç‹€æ…‹
curl http://localhost:9090/api/v1/targets | jq '.data.activeTargets[] | {job: .labels.job, health: .health}'

# æ¸¬è©¦æŒ‡æ¨™ç«¯é»
curl http://localhost:8000/metrics | head -20
```

**å•é¡Œ**: Grafana å„€è¡¨æ¿ç„¡æ³•è¼‰å…¥
```bash
# é‡ç½® Grafana é…ç½®
docker-compose -f docker-compose.main.yml restart grafana

# æª¢æŸ¥ Grafana æ—¥èªŒ
docker-compose -f docker-compose.main.yml logs grafana --tail=50

# æ‰‹å‹•å°å…¥å„€è¡¨æ¿ (å¦‚éœ€è¦)
# è¨ªå• http://localhost:3000 ä¸¦æ‰‹å‹•å°å…¥ JSON é…ç½®
```

### ğŸ”§ é€²éšæ•…éšœæ’é™¤

#### æ•ˆèƒ½èª¿æ ¡è¨ºæ–·
```bash
# 1. è­˜åˆ¥æ•ˆèƒ½ç“¶é ¸
curl -s http://localhost:9090/api/v1/query?query='topk(5, avg_over_time(api_call_duration_seconds[5m]))'

# 2. åˆ†æè¨˜æ†¶é«”ä½¿ç”¨æ¨¡å¼
docker stats --no-stream --format "table {{.Name}}\t{{.CPUPerc}}\t{{.MemUsage}}\t{{.MemPerc}}"

# 3. æª¢æŸ¥ç£ç¢Ÿ I/O
iostat -x 1 5

# 4. Neo4j æŸ¥è©¢æ•ˆèƒ½åˆ†æ
docker-compose -f docker-compose.main.yml exec neo4j \
  cypher-shell -u neo4j -p wazuh-graph-2024 \
  "CALL dbms.listQueries() YIELD query, elapsedTimeMillis WHERE elapsedTimeMillis > 1000 RETURN query, elapsedTimeMillis;"
```

#### è³‡æ–™ä¸€è‡´æ€§æª¢æŸ¥
```bash
# 1. æª¢æŸ¥ OpenSearch èˆ‡ Neo4j è³‡æ–™åŒæ­¥ç‹€æ…‹
docker-compose -f docker-compose.main.yml exec ai-agent \
  python -c "
from main import check_data_consistency
result = check_data_consistency()
print(f'è³‡æ–™ä¸€è‡´æ€§æª¢æŸ¥: {result}')
"

# 2. é©—è­‰å‘é‡ç´¢å¼•å®Œæ•´æ€§
curl -k -u admin:SecretPassword \
  "https://localhost:9200/wazuh-alerts-*/_search?size=0" | jq '.hits.total.value'

# 3. æª¢æŸ¥ Neo4j åœ–å½¢çµ±è¨ˆ
docker-compose -f docker-compose.main.yml exec neo4j \
  cypher-shell -u neo4j -p wazuh-graph-2024 \
  "MATCH (n) RETURN labels(n)[0] as NodeType, count(n) as Count ORDER BY Count DESC;"
```

---

## ç‰ˆæœ¬è®Šæ›´è¨˜éŒ„

### ğŸ“‹ ä¸»è¦ç‰ˆæœ¬ç™¼å¸ƒæ­·ç¨‹

#### v5.0 - çµ±ä¸€æ•´åˆç‰ˆæœ¬ (2024å¹´12æœˆ)
**é‡å¤§æ›´æ–°**:
- âœ… å®Œæˆ Stage 4 GraphRAG å¯¦ä½œ
- âœ… çµ±ä¸€ Docker Compose å †ç–Šæ•´åˆ
- âœ… å®Œæ•´ç›£æ§ç³»çµ± (Prometheus + Grafana)
- âœ… ç”Ÿç”¢ç’°å¢ƒéƒ¨ç½²å°±ç·’
- âœ… å…¨é¢æ–‡ä»¶æ•´åˆèˆ‡æ›´æ–°

**æ–°å¢åŠŸèƒ½**:
- Neo4j åœ–å½¢è³‡æ–™åº«å®Œæ•´æ•´åˆ
- Cypher è·¯å¾‘è¨˜è™Ÿå‰µæ–°è¡¨ç¤ºæ³•
- æ··åˆæª¢ç´¢å¼•æ“ (åœ–å½¢ + å‘é‡)
- çµ±ä¸€å•Ÿå‹•èˆ‡å¥åº·æª¢æŸ¥è…³æœ¬
- å®Œæ•´çš„æ•…éšœæ’é™¤æŒ‡å—

#### v4.0 - Stage 4 GraphRAG (2024å¹´11æœˆ)
**é‡å¤§æ›´æ–°**:
- âœ… GraphRAG åœ–å½¢å¨è„…åˆ†æå¯¦ä½œ
- âœ… Neo4j åœ–å½¢æŒä¹…å±¤æ•´åˆ
- âœ… åœ–å½¢åŸç”Ÿæª¢ç´¢å™¨å¯¦æ–½
- âœ… å¢å¼·æç¤ºè©æ¨¡æ¿

**æ•ˆèƒ½æå‡**:
- å¨è„…æª¢æ¸¬æº–ç¢ºæ€§æå‡è‡³ 94%+
- æ”»æ“Šè·¯å¾‘è­˜åˆ¥ç‡é”åˆ° 91%+
- åœ–å½¢æŸ¥è©¢å»¶é² < 15ms

#### v3.0 - Stage 3 AgenticRAG (2024å¹´10æœˆ)
**é‡å¤§æ›´æ–°**:
- âœ… Agentic ä»£ç†æ±ºç­–å¼•æ“
- âœ… å¤šç¶­åº¦æª¢ç´¢ç­–ç•¥ (8ç¨®)
- âœ… æ™ºèƒ½ä¸Šä¸‹æ–‡èšåˆ
- âœ… è‡ªå‹•åŒ–æª¢ç´¢ç­–ç•¥é¸æ“‡

**åŠŸèƒ½å¢å¼·**:
- ä¸Šä¸‹æ–‡ç›¸é—œæ€§æå‡è‡³ 89%
- æª¢ç´¢ç­–ç•¥å¾ 1 ç¨®æ“´å±•è‡³ 8 ç¨®
- åˆ†ææ·±åº¦æå‡ 200%

#### v2.0 - Stage 2 æ ¸å¿ƒRAG (2024å¹´9æœˆ)
**é‡å¤§æ›´æ–°**:
- âœ… æ ¸å¿ƒ RAG æª¢ç´¢å¢å¼·ç”Ÿæˆ
- âœ… OpenSearch k-NN å‘é‡æœç´¢
- âœ… æ­·å²è­¦å ±ä¸Šä¸‹æ–‡æª¢ç´¢
- âœ… LLM åˆ†æçµæœå„²å­˜

**æŠ€è¡“å¯¦ç¾**:
- HNSW å‘é‡ç´¢å¼•å»ºæ§‹
- é¤˜å¼¦ç›¸ä¼¼åº¦æª¢ç´¢æ¼”ç®—æ³•
- Claude 3 Haiku èˆ‡ Gemini æ•´åˆ

#### v1.0 - Stage 1 åŸºç¤å‘é‡åŒ– (2024å¹´8æœˆ)
**åˆå§‹ç‰ˆæœ¬**:
- âœ… åŸºç¤å‘é‡åŒ–ç³»çµ±
- âœ… Google Gemini Embedding æ•´åˆ
- âœ… Wazuh è­¦å ±é è™•ç†
- âœ… MRL æ”¯æ´å¯¦ä½œ

**åŸºç¤åŠŸèƒ½**:
- 768 ç¶­èªç¾©å‘é‡ç”Ÿæˆ
- Matryoshka Representation Learning
- è­¦å ±æ–‡æœ¬çµæ§‹åŒ–è™•ç†

### ğŸ”® æœªä¾†ç‰ˆæœ¬è¦åŠƒ

#### v6.0 - ä¼æ¥­ç´šæ“´å±• (2025å¹´Q1)
**è¨ˆåŠƒåŠŸèƒ½**:
- å¤šç§Ÿæˆ¶æ¶æ§‹æ”¯æ´
- é«˜å¯ç”¨æ€§éƒ¨ç½²é…ç½®
- é€²éšå¨è„…çµæ•æ¨¡å¼
- è‡ªå‹•åŒ–å›æ‡‰æ•´åˆ (SOAR)

#### v7.0 - å¤šæ¨¡æ…‹åˆ†æ (2025å¹´Q2)
**è¨ˆåŠƒåŠŸèƒ½**:
- æª”æ¡ˆå…§å®¹åˆ†ææ•´åˆ
- ç¶²è·¯æµé‡åœ–è­œåˆ†æ
- å¤–éƒ¨å¨è„…æƒ…å ±èåˆ
- å¯¦æ™‚å”ä½œå¹³å°

---

## ğŸ“š åƒè€ƒè³‡æºèˆ‡é™„éŒ„

### ğŸ”— æŠ€è¡“æ–‡ä»¶é€£çµ
- [Wazuh å®˜æ–¹æ–‡ä»¶](https://documentation.wazuh.com)
- [Neo4j åœ–å½¢è³‡æ–™åº«æŒ‡å—](https://neo4j.com/docs)
- [OpenSearch å‘é‡æœç´¢](https://opensearch.org/docs/latest/search-plugins/knn)
- [Google Gemini API](https://ai.google.dev/docs)
- [Anthropic Claude API](https://docs.anthropic.com)

### ğŸ“Š æ•ˆèƒ½åŸºæº–æ¸¬è©¦å ±å‘Š
è©³ç´°çš„æ•ˆèƒ½æ¸¬è©¦çµæœèˆ‡åˆ†æè«‹åƒè€ƒï¼š
- [GraphRAG æ•ˆèƒ½åŸºæº–æ¸¬è©¦](./performance-benchmarks.md)
- [å‘é‡åŒ–æ•ˆèƒ½åˆ†æ](./vectorization-performance.md)
- [ç³»çµ±è³‡æºä½¿ç”¨å ±å‘Š](./resource-utilization-report.md)

### ğŸ› ï¸ é–‹ç™¼è€…è³‡æº
- [API æ–‡ä»¶](./api-documentation.md)
- [æ“´å±•é–‹ç™¼æŒ‡å—](./extension-development.md)
- [è²¢ç»è€…æŒ‡å—](./contributing.md)

---

*æ–‡ä»¶ç‰ˆæœ¬: v5.0*  
*æœ€å¾Œæ›´æ–°: 2024å¹´12æœˆ*  
*ç¶­è­·åœ˜éšŠ: Wazuh GraphRAG é–‹ç™¼çµ„*

---

> ğŸ“ **æ³¨æ„**: æœ¬æ–‡ä»¶ç‚ºæ‰€æœ‰å°ˆæ¡ˆ .md æ–‡ä»¶çš„æ•´åˆç‰ˆæœ¬ï¼ŒåŒ…å«å®Œæ•´çš„æŠ€è¡“è³‡æ–™èˆ‡æ“ä½œæŒ‡å—ã€‚å¦‚éœ€ç‰¹å®šä¸»é¡Œçš„è©³ç´°è³‡è¨Šï¼Œè«‹åƒè€ƒå°æ‡‰çš„åŸå§‹æ–‡ä»¶ã€‚